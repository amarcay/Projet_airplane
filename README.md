# ğŸ›« Pipeline Big Data AÃ©ronautique â€” Traitement Temps RÃ©el

[![Docker](https://img.shields.io/badge/Docker-Compose-2496ED?logo=docker&logoColor=white)](https://www.docker.com/)
[![Apache Spark](https://img.shields.io/badge/Apache-Spark_3.5.0-E25A1C?logo=apachespark&logoColor=white)](https://spark.apache.org/)
[![Kafka](https://img.shields.io/badge/Apache-Kafka-231F20?logo=apachekafka&logoColor=white)](https://kafka.apache.org/)
[![PostgreSQL](https://img.shields.io/badge/PostgreSQL-15-4169E1?logo=postgresql&logoColor=white)](https://www.postgresql.org/)

---

## ğŸ“‹ Table des matiÃ¨res

- [Vue d'ensemble](#-vue-densemble)
- [Architecture](#-architecture-technique)
- [Stack technologique](#-stack-technologique)
- [PrÃ©requis](#-prÃ©requis)
- [Installation et dÃ©marrage](#-installation-et-dÃ©marrage)
- [Pipeline dÃ©taillÃ©](#-pipeline-dÃ©taillÃ©)
- [Visualisation Grafana](#-visualisation-grafana)
- [DÃ©bogage](#-dÃ©bogage--astuces)
- [AmÃ©liorations futures](#-amÃ©liorations-futures)
- [Ressources](#-ressources-utiles)
- [Contributeurs](#-contributeurs)

---

## ğŸ¯ Vue d'ensemble

Ce projet implÃ©mente un **pipeline de traitement distribuÃ© de donnÃ©es aÃ©ronautiques en temps rÃ©el** utilisant les technologies Big Data les plus performantes du marchÃ©. L'objectif est de dÃ©montrer la maÃ®trise complÃ¨te d'une chaÃ®ne de traitement moderne, de l'ingestion Ã  la visualisation.

### ğŸ”„ Flux de donnÃ©es

```
API AÃ©ronautique â†’ NiFi â†’ Kafka â†’ Spark Streaming â†’ PostgreSQL â†’ Grafana
     (source)    (ETL)  (broker) (transformation)  (stockage)  (viz)
```

### ğŸ“ Objectifs pÃ©dagogiques

- âœ… MaÃ®triser l'orchestration de flux avec **Apache NiFi**
- âœ… Comprendre le fonctionnement d'un **message broker** (Kafka)
- âœ… Traiter des streams en temps rÃ©el avec **Spark Structured Streaming**
- âœ… Persister des donnÃ©es dans une base **PostgreSQL**
- âœ… CrÃ©er des dashboards interactifs avec **Grafana**
- âœ… Orchestrer une architecture microservices avec **Docker Compose**

---

## ğŸ—ï¸ Architecture technique

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         PIPELINE BIG DATA                               â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜

â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   API Ext.   â”‚â”€â”€â”€â”€â”€â–¶â”‚    NiFi     â”‚â”€â”€â”€â”€â”€â–¶â”‚    Kafka     â”‚
â”‚ AviationStackâ”‚      â”‚ :8443       â”‚      â”‚ :9092/:9093  â”‚
â”‚   OpenAIP    â”‚      â”‚             â”‚      â”‚              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜      â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                                   â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
                      â”‚
                      â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”       â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚ Spark Cluster â”‚â”€â”€â”€â”€â”€â”€â–¶â”‚  PostgreSQL  â”‚
              â”‚ Master :8080  â”‚       â”‚    :5432     â”‚
              â”‚ Worker :8081  â”‚       â”‚              â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜       â””â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”˜
                                             â”‚
                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”
                      â”‚                               â”‚
                      â–¼                               â–¼
              â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”             â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
              â”‚    pgAdmin    â”‚             â”‚   Grafana   â”‚
              â”‚     :5050     â”‚             â”‚    :3000    â”‚
              â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜             â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

---

## ğŸ§© Stack technologique

| Composant | Technologie | Version | RÃ´le |
|-----------|-------------|---------|------|
| <img src="https://nifi.apache.org/images/apache-nifi-drop-logo.svg" width="50"> | **Apache NiFi** | 1.28.0 | Orchestration et ingestion des flux de donnÃ©es |
| <img src="https://upload.wikimedia.org/wikipedia/commons/0/01/Apache_Kafka_logo.svg" width="50"> | **Apache Kafka** | 7.5.0 (Confluent) | Message broker distribuÃ© pour streaming |
| <img src="https://zookeeper.apache.org/images/zookeeper_small.gif" width="50"> | **Apache ZooKeeper** | 7.5.0 | Coordination et gestion de l'Ã©tat Kafka |
| <img src="https://spark.apache.org/images/spark-logo-trademark.png" width="50"> | **Apache Spark** | 3.5.0 | Traitement distribuÃ© en temps rÃ©el |
| <img src="https://www.postgresql.org/media/img/about/press/elephant.png" width="50"> | **PostgreSQL** | 15 | Base de donnÃ©es relationnelle |
| ğŸ› ï¸ | **pgAdmin** | Latest | Interface web d'administration PostgreSQL |
| <img src="https://upload.wikimedia.org/wikipedia/commons/9/9d/Grafana_logo.png" width="50"> | **Grafana** | Enterprise (latest) | Dashboards et visualisation temps rÃ©el |
| <img src="https://upload.wikimedia.org/wikipedia/commons/7/79/Docker_%28container_engine%29_logo.png"> | **Docker Compose** | - | Orchestration de l'infrastructure |

---

## ğŸ“¦ PrÃ©requis

### Ports Ã  libÃ©rer

Assurez-vous que les ports suivants sont disponibles :

| Port | Service | Description |
|------|---------|-------------|
| `2181` | ZooKeeper | Coordination Kafka |
| `9092` | Kafka | AccÃ¨s externe |
| `9093` | Kafka | Communication inter-services |
| `8443` | NiFi | Interface web (HTTPS) |
| `7077` | Spark Master | Cluster Spark |
| `8080` | Spark Master UI | Interface web |
| `8081` | Spark Worker | NÅ“ud de calcul |
| `5432` | PostgreSQL | Base de donnÃ©es |
| `5050` | pgAdmin | Interface d'administration |
| `3000` | Grafana | Dashboards |

---
# AJOUT THOMAS

---

##  Collecte des donnÃ©es avec Apache NiFi

**ğŸ¯ Objectif :** RÃ©cupÃ©rer et prÃ©parer les donnÃ©es issues de diffÃ©rentes API aÃ©ronautiques avant leur diffusion vers Kafka.

### Fonctions principales
- Connexion Ã  plusieurs sources dâ€™API.
- Filtrage et enrichissement lÃ©ger des flux.
- Transformation des donnÃ©es en JSON structurÃ©.
- Envoi vers Kafka pour diffusion en temps rÃ©el.

### ChaÃ®ne de traitement NiFi
- **InvokeHTTP** â†’ interroge lâ€™API pour rÃ©cupÃ©rer les donnÃ©es brutes.  
- **EvaluateJsonPath** â†’ extrait les champs pertinents du JSON.  
- **AttributesToJSON** â†’ reformate les donnÃ©es extraites en flux JSON.  
- **PublishKafkaRecord** â†’ publie les messages sur un *topic* Kafka.  
- **LogAttribute** â†’ permet le suivi et le dÃ©bogage du flux.

---

## âš¡ Diffusion en temps rÃ©el avec Apache Kafka

** Objectif :** Servir de couche intermÃ©diaire entre NiFi et Spark pour la diffusion des flux de donnÃ©es.

### Fonctionnement
- **Producteurs** : NiFi envoie les donnÃ©es vers Kafka.  
- **Topics** : organisation des flux par type (vols, aÃ©roports, frÃ©quences, etc.).  
- **Consommateurs** : Spark lit les messages pour les transformer en continu.

Kafka assure une **mise en file dâ€™attente fiable** et garantit la **diffusion en temps rÃ©el** des donnÃ©es aÃ©ronautiques.

---

##  Traitement et intÃ©gration avec Apache Spark Structured Streaming

** Objectif :** Nettoyer, transformer et insÃ©rer les donnÃ©es dans la base PostgreSQL en temps rÃ©el.

Le script **`Streaming-processor.py`** assure le traitement des donnÃ©es issues de Kafka avant leur stockage.

### Ã‰tapes principales du pipeline Spark

- **âš™ï¸ Configuration** â†’ Chargement des dÃ©pendances pour Kafka et PostgreSQL.  
- **ğŸ“ DÃ©finition du schÃ©ma** â†’ Description de la structure des donnÃ©es dâ€™aÃ©roports.  
- **ğŸ” Lecture** â†’ RÃ©cupÃ¨re les flux JSON depuis Kafka.  
- **ğŸ§© Transformation** â†’ Nettoie et uniformise les champs importants.  
- **ğŸ’¾ Ã‰criture** â†’ InsÃ¨re les donnÃ©es transformÃ©es dans PostgreSQL.  
- **â™»ï¸ ExÃ©cution continue** â†’ Laisse tourner le streaming pour un flux en temps rÃ©el.

---

## ğŸ—„ï¸ Stockage et gestion avec PostgreSQL + pgAdmin

** Objectif :** Assurer la **persistance** et la **structuration** des donnÃ©es traitÃ©es.

### FonctionnalitÃ©s
- **PostgreSQL** sert de base de donnÃ©es relationnelle principale.  
- **pgAdmin** permet dâ€™explorer les tables, exÃ©cuter des requÃªtes et valider les donnÃ©es.  

Cette couche garantit une **historisation complÃ¨te** et un accÃ¨s simplifiÃ© pour les analyses et visualisations ultÃ©rieures.

---

## ğŸ“Š Visualisation avec Grafana

** Objectif :** Transformer les donnÃ©es stockÃ©es en **indicateurs visuels dynamiques**.

### FonctionnalitÃ©s principales
- CrÃ©ation de **dashboards interactifs** pour le suivi du trafic aÃ©rien.  
- Visualisation de **cartes**, **graphiques**, **statistiques** et **tendances**.  
- Mise en place dâ€™**alertes** et de **KPI** pour la surveillance en temps rÃ©el.  
- Connexion directe Ã  PostgreSQL pour un rafraÃ®chissement automatique des donnÃ©es.

Grafana permet une **analyse intuitive** et une **prise de dÃ©cision rapide**, tout en offrant une vision globale de lâ€™activitÃ© aÃ©ronautique.

---

## ğŸ§  Vue dâ€™ensemble du pipeline




---

## ğŸš€ Installation et dÃ©marrage

### 1ï¸âƒ£ Cloner le projet

```bash
git clone https://github.com/votre-repo/pipeline-big-data-aero.git
cd pipeline-big-data-aero
```

### 2ï¸âƒ£ DÃ©marrer l'infrastructure

```bash
# Lancer tous les services en arriÃ¨re-plan
docker compose up -d

# VÃ©rifier l'Ã©tat des conteneurs
docker compose ps

# Suivre les logs en temps rÃ©el
docker compose logs -f
```

### 3ï¸âƒ£ VÃ©rification du dÃ©marrage

Attendez environ **2-3 minutes** que tous les services soient opÃ©rationnels, puis vÃ©rifiez :

```bash
# Tous les conteneurs doivent Ãªtre "Up"
docker compose ps

# Kafka doit Ãªtre prÃªt
docker exec -it kafka kafka-topics.sh --bootstrap-server localhost:9092 --list
```

### 4ï¸âƒ£ AccÃ¨s aux interfaces web

| Interface | URL | Identifiants par dÃ©faut |
|-----------|-----|------------------------|
| ğŸŒŠ **NiFi** | https://localhost:8443/nifi | Auto-gÃ©nÃ©rÃ© (voir logs) |
| ğŸ—„ï¸ **pgAdmin** | http://localhost:5050 | `admin@example.com` / `admin` |
| âš¡ **Spark Master** | http://localhost:8080 | Aucun |
| ğŸ“Š **Grafana** | http://localhost:3000 | `admin` / `admin` |

**Note NiFi** : Pour rÃ©cupÃ©rer le mot de passe auto-gÃ©nÃ©rÃ© :
```bash
docker logs nifi 2>&1 | grep -i "Generated Username"
```

### 5ï¸âƒ£ ArrÃªt de l'infrastructure

```bash
# ArrÃªter tous les services
docker compose down

# ArrÃªter ET supprimer les volumes (âš ï¸ perte de donnÃ©es)
docker compose down -v
```

---

## ğŸ”„ Pipeline dÃ©taillÃ©

### 1ï¸âƒ£ Apache NiFi â€” Ingestion des donnÃ©es

#### Configuration initiale

1. **AccÃ©der Ã  NiFi** : https://localhost:8443/nifi
2. **Importer le template** : `src/nifi/Template_airport.xml`
   - Clic droit sur le canvas â†’ Upload Template
   - DÃ©poser le fichier XML
3. **Instancier le template** : glisser l'icÃ´ne de template sur le canvas

#### Architecture du flux NiFi

![SchÃ©ma du template NiFi pour ingestion API â†’ Kafka](image/template_airport.png)


```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚  InvokeHTTP     â”‚  â† Interroge l'API externe (GET)
â”‚  (API Call)     â”‚     Config: URL, Headers, API Key
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   SplitJson     â”‚  â† DÃ©coupe le JSON en Ã©lÃ©ments individuels
â”‚                 â”‚     JsonPath: $.data[*]
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚ EvaluateJsonPathâ”‚  â† Extrait les champs importants
â”‚                 â”‚     Ex: $.icao, $.name, $.latitude
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚AttributesToJSON â”‚  â† Reconstruit un JSON normalisÃ©
â”‚                 â”‚     Destination: flowfile-content
â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜
         â”‚
         â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚PublishKafkaRec  â”‚  â† Publie vers Kafka
â”‚    :9093        â”‚     Topic: airportInt / airportnyc
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜     Bootstrap: kafka:9093
```

#### Configuration des processeurs clÃ©s

**InvokeHTTP** :
- Remote URL : `https://api.aviationstack.com/v1/flights` (exemple)
- HTTP Method : `GET`
- Request Header : `X-API-Key: VOTRE_CLE_API`

**PublishKafkaRecord_2_0** :
- Kafka Brokers : `kafka:9093`
- Topic Name : `airportInt` (ou `airportnyc`)
- Record Reader : `JsonTreeReader`
- Record Writer : `JsonRecordSetWriter`

#### DÃ©marrage du flux

1. SÃ©lectionner tous les processeurs (Ctrl+A)
2. Clic droit â†’ Start
3. VÃ©rifier dans les queues que les FlowFiles transitent

#### VÃ©rification dans Kafka

```bash
# Lister les topics
docker exec -it kafka kafka-topics.sh \
  --bootstrap-server localhost:9092 --list

# Consommer les messages du topic
docker exec -it kafka kafka-console-consumer.sh \
  --bootstrap-server localhost:9092 \
  --topic airportInt \
  --from-beginning \
  --max-messages 5
```

---

### 2ï¸âƒ£ Apache Kafka â€” Message Broker

#### RÃ´le dans le pipeline

Kafka agit comme un **tampon de messages asynchrone** entre NiFi (producteur) et Spark (consommateur), offrant :

- âœ… **DÃ©couplage** : NiFi et Spark peuvent fonctionner Ã  des rythmes diffÃ©rents
- âœ… **RÃ©silience** : Les messages sont persistÃ©s sur disque
- âœ… **ScalabilitÃ©** : Ajout de partitions et de brokers Ã  la demande
- âœ… **Replay** : PossibilitÃ© de rejouer les messages depuis un offset donnÃ©

#### Topics utilisÃ©s

| Topic | Source | Consommateur | Description |
|-------|--------|--------------|-------------|
| `airportInt` | NiFi (OpenAIP) | Spark (`app.py`) | DonnÃ©es d'aÃ©roports internationaux |
| `airportnyc` | NiFi (AviationStack) | Spark (`appnyc.py`) | DonnÃ©es de vols NYC |

#### Configuration rÃ©seau

```yaml
# AccÃ¨s depuis l'extÃ©rieur du rÃ©seau Docker
KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://localhost:9092,PLAINTEXT_INTERNAL://kafka:9093

# NiFi et Spark utilisent kafka:9093 (rÃ©seau interne)
# Les outils CLI locaux utilisent localhost:9092
```

#### Commandes utiles

```bash
# CrÃ©er un topic manuellement
docker exec -it kafka kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --create --topic mon-topic --partitions 3 --replication-factor 1

# DÃ©crire un topic
docker exec -it kafka kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --describe --topic airportInt

# Supprimer un topic
docker exec -it kafka kafka-topics.sh \
  --bootstrap-server localhost:9092 \
  --delete --topic mon-topic
```

---

### 3ï¸âƒ£ Apache Spark â€” Traitement temps rÃ©el

#### Architecture Spark

Le cluster Spark se compose de :
- **Master** : coordonne les jobs et alloue les ressources
- **Worker(s)** : exÃ©cutent les tÃ¢ches de calcul
- **Driver** : pilote l'application (dans le conteneur master lors du submit)

#### Jobs disponibles

| Script | Topic source | Tables cibles | Description |
|--------|-------------|---------------|-------------|
| `app.py` | `airportInt` | `airportsInt`, `frequencies`, `runways` | Traite les donnÃ©es OpenAIP (structure imbriquÃ©e) |
| `appnyc.py` | `airportnyc` | `flights` | Traite les donnÃ©es AviationStack (vols NYC) |

#### Soumission d'un job â€” AÃ©roports

```bash
# 1. Copier le script dans le conteneur
docker cp src/spark/app.py spark-master:/opt/spark-apps/app.py

# 2. Soumettre le job au cluster
docker exec -it spark-master bash -lc "\
  /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0 \
  /opt/spark-apps/app.py"
```

#### Soumission d'un job â€” Vols NYC

```bash
# 1. Copier le script
docker cp src/spark/appnyc.py spark-master:/opt/spark-apps/appnyc.py

# 2. Soumettre
docker exec -it spark-master bash -lc "\
  /opt/spark/bin/spark-submit \
  --master spark://spark-master:7077 \
  --packages org.apache.spark:spark-sql-kafka-0-10_2.12:3.5.0,org.postgresql:postgresql:42.6.0 \
  /opt/spark-apps/appnyc.py"
```

#### Ã‰tapes du traitement Spark

```python
# 1ï¸âƒ£ Configuration Spark Session
spark = SparkSession.builder \
    .appName("AirportProcessing") \
    .config("spark.jars.packages", "...") \
    .getOrCreate()

# 2ï¸âƒ£ Lecture du stream Kafka
kafka_df = spark.readStream \
    .format("kafka") \
    .option("kafka.bootstrap.servers", "kafka:9093") \
    .option("subscribe", "airportInt") \
    .load()

# 3ï¸âƒ£ Parsing JSON et extraction de schÃ©ma
parsed_df = kafka_df.select(
    from_json(col("value").cast("string"), airport_schema).alias("data")
).select("data.*")

# 4ï¸âƒ£ Transformations (nettoyage, normalisation)
clean_df = parsed_df \
    .filter(col("icao_code").isNotNull()) \
    .withColumn("latitude", col("latitude").cast("double")) \
    .withColumn("longitude", col("longitude").cast("double"))

# 5ï¸âƒ£ Ã‰criture dans PostgreSQL
query = clean_df.writeStream \
    .foreachBatch(write_to_postgres) \
    .outputMode("append") \
    .start()

query.awaitTermination()
```

#### Monitoring du job

- **Spark UI** : http://localhost:8081
  - Voir les jobs actifs, completed, failed
  - MÃ©triques : stages, tasks, shuffle, memory
- **Logs** :
  ```bash
  docker logs -f spark-master
  docker logs -f spark-worker
  ```

---

#### Configuration pgAdmin

1. **Connexion** : http://localhost:5050
   - Email : `admin@example.com`
   - Password : `admin`

2. **Ajouter le serveur PostgreSQL** :
   - Clic droit sur "Servers" â†’ Create â†’ Server
   - **General** tab :
     - Name : `Aviation DB`
   - **Connection** tab :
     - Host : `postgres` (nom du service Docker)
     - Port : `5432`
     - Database : `mydb`
     - Username : `admin`
     - Password : `admin`

3. **Explorer les donnÃ©es** :
   - Servers â†’ Aviation DB â†’ Databases â†’ mydb â†’ Schemas â†’ public â†’ Tables

#### RequÃªtes SQL utiles

```sql
-- Compter le nombre d'aÃ©roports par pays
SELECT country, COUNT(*) as nb_airports
FROM airportsInt
GROUP BY country
ORDER BY nb_airports DESC
LIMIT 10;

-- AÃ©roports dans une zone gÃ©ographique
SELECT name, latitude, longitude
FROM airportsInt
WHERE latitude BETWEEN 40.0 AND 50.0
  AND longitude BETWEEN -5.0 AND 10.0;

-- Statistiques de vols
SELECT 
    status,
    COUNT(*) as nb_flights,
    COUNT(DISTINCT airline) as nb_airlines
FROM flights
GROUP BY status;
```

---

## ğŸ“Š Visualisation Grafana

### Configuration initiale

#### 1ï¸âƒ£ Connexion et changement de mot de passe

1. AccÃ©der Ã  http://localhost:3000
2. Login : `admin` / `admin`
3. Changer le mot de passe (ou cliquer sur "Skip")

#### 2ï¸âƒ£ Ajouter la datasource PostgreSQL

1. Menu **â˜°** â†’ **Connections** â†’ **Data sources** â†’ **Add data source**
2. SÃ©lectionner **PostgreSQL**
3. Configuration :
   ```
   Name:     Aviation Database
   Host:     postgres:5432
   Database: mydb
   User:     admin
   Password: admin
   TLS/SSL:  disable
   ```
4. **Save & Test** (doit afficher "Database Connection OK")

#### 3ï¸âƒ£ Importer le dashboard

1. Menu **â˜°** â†’ **Dashboards** â†’ **Import**
2. **Upload JSON file** : sÃ©lectionner `src/grafana/Airport_Dashboard.json`
3. Choisir la datasource **Aviation Database**
4. **Import**

### Personnalisation avancÃ©e

---

### Commandes de diagnostic

```bash
# Ã‰tat global des conteneurs
docker compose ps

# Logs d'un service spÃ©cifique
docker logs -f <service_name>

# Statistiques de ressources
docker stats

# Inspecter un rÃ©seau Docker
docker network inspect pipeline-big-data-aero_default

# ExÃ©cuter une commande dans un conteneur
docker exec -it <container_name> bash

# RedÃ©marrer un service
docker compose restart <service_name>

# RecrÃ©er un service (âš ï¸ perte de donnÃ©es)
docker compose up -d --force-recreate <service_name>
```

### Monitoring de la santÃ© du pipeline

```bash
# 1. VÃ©rifier que NiFi envoie des messages
docker logs nifi | grep "PublishKafka"

# 2. VÃ©rifier le lag Kafka (messages en attente)
docker exec -it kafka kafka-consumer-groups.sh \
  --bootstrap-server localhost:9092 \
  --describe --group spark-streaming

# 3. VÃ©rifier l'activitÃ© Spark
curl -s http://localhost:8080/json/ | jq '.activeapps[] | {name, starttime, duration}'

# 4. VÃ©rifier les connexions PostgreSQL
docker exec -it postgres psql -U admin -d mydb -c \
  "SELECT count(*) FROM pg_stat_activity WHERE datname='mydb';"
```

---

## ğŸ“š Ressources utiles

### Documentation officielle

- [Apache NiFi Documentation](https://nifi.apache.org/docs.html)
- [Apache Kafka Quickstart](https://kafka.apache.org/quickstart)
- [Spark Structured Streaming Guide](https://spark.apache.org/docs/latest/structured-streaming-programming-guide.html)
- [PostgreSQL Documentation](https://www.postgresql.org/docs/)
- [Grafana Tutorials](https://grafana.com/tutorials/)

### APIs de donnÃ©es aÃ©ronautiques

- [AviationStack](https://aviationstack.com/) - DonnÃ©es de vols temps rÃ©el
- [OpenAIP](https://www.openaip.net/) - DonnÃ©es d'aÃ©roports open source

---

## ğŸ“ Structure du projet

```
pipeline-big-data-aero/
â”œâ”€â”€ docker-compose.yml          # Orchestration des services
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ nifi/
â”‚   â”‚   â””â”€â”€ Template_airport.xml    # Template flux NiFi
â”‚   â”œâ”€â”€ spark/
â”‚   â”‚   â”œâ”€â”€ app.py                  # Job aÃ©roports (OpenAIP)
â”‚   â”‚   â””â”€â”€ appnyc.py               # Job vols (AviationStack)
â”‚   â””â”€â”€ grafana/
â”‚       â””â”€â”€ Airport_Dashboard.json  # Dashboard Grafana
â””â”€â”€ README.md                   # Ce fichier
```

---

## ğŸ‘¥ Contributeurs

Ce projet a Ã©tÃ© rÃ©alisÃ© dans le cadre du cours **DonnÃ©es DistribuÃ©es** :

- **Alphonse MarÃ§ay** - [GitHub](https://github.com/amarcay)
- **Thomas Bourvon** - [GitHub](https://github.com/Thomas-Brvn)

---

## ğŸ“„ Licence

Projet acadÃ©mique Ã  usage pÃ©dagogique uniquement.  
Les logos et marques appartiennent Ã  leurs propriÃ©taires respectifs.
